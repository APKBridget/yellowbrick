# yellowbrick.regressor
# Visualizations related to evaluating Scikit-Learn regressor models
#
# Author:   Benjamin Bengfort <bbengfort@districtdatalabs.com>
# Created:  Fri Jun 03 10:30:36 2016 -0700
#
# Copyright (C) 2016 District Data Labs
# For license information, see LICENSE.txt
#
# ID: regressor.py [4a59c49] benjamin@bengfort.com $

"""
Visualizations related to evaluating Scikit-Learn regressor models
"""

##########################################################################
## Imports
##########################################################################

import matplotlib as mpl
import matplotlib.pyplot as plt

from .bestfit import draw_best_fit
from .exceptions import YellowbrickTypeError
from .utils import get_model_name, isestimator, isregressor
from .base import Visualizer, ScoreVisualizer, MultiModelMixin
# from sklearn.cross_validation import train_test_split as tts

##########################################################################
## Regression Visualization Base Object
##########################################################################

class RegressionScoreVisualizer(ScoreVisualizer):
    def __init__(self, model):
        """
        Check to see if model is an instance of a regressor.
        Should return an error if it isn't.
        """
        if not isregressor(model):
            raise YellowbrickTypeError(
                "This estimator is not a regressor; try a classifier or clustering score visualizer instead!"
        )

##########################################################################
## Prediction Error Plots
##########################################################################

class PredictionError(RegressionScoreVisualizer):
    """
    Plot the actual targets from the dataset against the
    predicted values generated by our model(s).
    """
    def __init__(self, model, **kwargs):
        self.estimator = model
        self.name = get_model_name(self.estimator)
        self.colors = {
            'point': kwargs.pop('point_color', '#F2BE2C'),
            'line': kwargs.pop('line_color', '#2B94E9'),
        }
        self.fig, self.ax = plt.subplots()

    def score(self, y, y_pred=None, **kwargs):
        """
        Originally score  for prediction error was conceived as generating
        y_pred by calling the sklearn function cross_val_predict on the
        model, X, y, and the specified number of folds, e.g.:

            y_pred = cv.cross_val_predict(model, X, y, cv=12)

        With the new API, there's not much for score to do.

        """
        self._draw(y,y_pred)

    def _draw(self, y, y_pred):
        """
        If score is happening inside a loop, _draw would get called multiple times.

        But, ideally we'd want the best fit line to be drawn only once?
        """
        self.ax.scatter(y, y_pred, c='#F2BE2C')
        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'])
        return self.ax

    def poof(self):
        self.ax.set_xlim(y.min()-1, y.max()+1)
        self.ax.set_ylim(y_pred.min()-1, y_pred.max()+1)
        self.ax.set_title('Prediction Error for {}'.format(self.name))
        self.ax.set_ylabel('Predicted')
        plt.xlabel('Measured')
        return plt

##########################################################################
## Residuals Plots
##########################################################################

class ResidualsPlot(RegressionScoreVisualizer):
    def __init__(self, model, **kwargs):
        self.estimator = model
        self.name = get_model_name(self.estimator)
        self.colors = {
            'train_point': kwargs.pop('train_point_color', '#2B94E9'),
            'test_point': kwargs.pop('test_point_color', '#94BA65'),
            'line': kwargs.pop('line_color', '#333333'),
        }
        self.fig, self.ax = plt.subplots()

    def score(self, y, y_pred, y_test=None, y_test_pred=None):
        """
        Is there a better way to differentiate between train and test points?

        We'd like to color them differently in _draw...
        Can the user pass those in as keyword arguments?
        """
        self._draw(y, y_pred, y_test, y_test_pred)

    def _draw(self, y, y_pred, y_test, y_test_pred):
        """
        Originally residuals plot was conceived as generating the
        train and test sets (in the `fit` method),
        and then fitting and predicting on both in the `render` method:

        With the new API, I think we want that to happen outside of yellowbrick.

        However, I'm not keen on the fact that now the user has to pass
        all four ys into `score` now to paint train and test different colors.
        """
        self.ax.scatter(y_pred, y_pred - y, c=self.colors['train_point'], s=40, alpha=0.5)
        if y_test is not None:
            self.ax.scatter(y_test, y_test_pred - y_test, c=self.colors['test_point'], s=40)
        else:
            pass

        return self.ax

    def poof(self):
        """
        The user calls poof
        """
        self.ax.hlines(y=0, xmin=0, xmax=100)
        self.ax.set_title('Residuals for {} Model'.format(self.name))
        self.ax.set_ylabel('Residuals')
        plt.xlabel("Predicted Value")

        return plt
